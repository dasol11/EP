{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5b73c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearnex import patch_sklearn \n",
    "patch_sklearn()\n",
    "\n",
    "\n",
    "# Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# Randomforest Regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Support Vector Regression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# hyper parameter tunning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ARIMA\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "# LSTM\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout\n",
    "# from keras.layers import LSTM\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Jul 31 16:43:28 2022\n",
    "\n",
    "@author: Junhyun\n",
    "\"\"\"\n",
    "class TimeSeriesRegression():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "    \n",
    "    def TimeSeriesDataTransform(self, data, lag):\n",
    "        \"\"\"\n",
    "        ※ 참조 코드 : http://103.60.126.183:8150/gidatalab (LSTM)\n",
    "        \n",
    "        데이터를 변환하기 위해서는 Y값이 맨 왼쪽에 위치해있어야함 \n",
    "        \n",
    "        To transoform data to timeseries data, target data(Y) have to be located at leftmost\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : DataFrame\n",
    "            data\n",
    "        lag : int\n",
    "            시계열 예측에서 데이터를 미는 시점 (= Time sequence)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        agg : 시계열 에측이 가능하도록 변환된 데이터\n",
    "\n",
    "        \"\"\"\n",
    "        if isinstance(self.data, np.ndarray):\n",
    "            data = pd.DataFrame(self.data)\n",
    "        elif isinstance(self.data, pd.core.series.Series):\n",
    "            data = pd.DataFrame(self.data)\n",
    "        \n",
    "        n_vars = 1 if type(data) is list else data.shape[1]\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        cols, names = list(), list()\n",
    "\n",
    "        # 입력값의 순서 (t-n, ... t-1)\n",
    "        for i in range(lag, 0, -1):\n",
    "            cols.append(df.shift(i))\n",
    "            names += [('%s(t-%d)' % (data.columns[j], i)) for j in range(n_vars)]\n",
    "\n",
    "        # 예측의 순서 (t, t+1, ... t+n)\n",
    "        for i in range(0, 1):\n",
    "            cols.append(df.shift(-i))\n",
    "            if i == 0:\n",
    "                names += [('%s(t)' % (data.columns[j])) for j in range(n_vars)]\n",
    "            else:\n",
    "                names += [('%s(t+%d)' % (data.columns[j], i)) for j in range(n_vars)]\n",
    "\n",
    "        # 합치기\n",
    "        agg = pd.concat(cols, axis=1)\n",
    "        agg.columns = names\n",
    "\n",
    "        # NaN 값의 row를 제거\n",
    "        agg.dropna(inplace=True)\n",
    "        \n",
    "        # 인덱스 초기화\n",
    "        agg = agg.reset_index(drop=True)\n",
    "        \n",
    "        agg = agg.iloc[:,0:(data.shape[1]*lag)+1]\n",
    "\n",
    "        return agg\n",
    "\n",
    "        \n",
    "    # Ridge Regression\n",
    "    def Ridge_regression(self, X_train, X_test, y_train, y_test):\n",
    "\n",
    "        alphas = np.arange(0, 1, 0.03)\n",
    "        ridgecv = RidgeCV(alphas = alphas, cv = 5) \n",
    "        ridgecv.fit(X_train, y_train)\n",
    "        print(\"alpha : %.2f\" % ridgecv.alpha_)\n",
    "\n",
    "        ridge_train_pred = ridgecv.predict(X_train)\n",
    "        ridge_test_pred = ridgecv.predict(X_test)\n",
    "\n",
    "        return({'trainPrediction':ridge_train_pred, 'testPrediction':ridge_test_pred})\n",
    "    \n",
    "    # Random Forest Regression\n",
    "    def Randomforest_regression(self, X_train, X_test, y_train, y_test):\n",
    "\n",
    "        params = {\n",
    "            'n_estimators' : [100],\n",
    "            'max_depth' : [6,8,10,12],\n",
    "            'min_samples_leaf' : [8,12,8],\n",
    "            'min_samples_split' : [8,16,20]\n",
    "        }\n",
    "\n",
    "        rf = RandomForestRegressor()\n",
    "        grid_cv = GridSearchCV(rf, param_grid=params, cv=5)\n",
    "        grid_cv.fit(X_train, y_train)\n",
    "        print(\"최적 하이퍼 파라미터:\\n\", grid_cv.best_params_)\n",
    "\n",
    "        rf_train_pred = grid_cv.predict(X_train)\n",
    "        rf_test_pred = grid_cv.predict(X_test)\n",
    "\n",
    "        return({'trainPrediction':rf_train_pred, 'testPrediction':rf_test_pred})\n",
    "    \n",
    "    # Support Vector Regression\n",
    "    def Supportvector_regression(self, X_train, X_test, y_train, y_test):\n",
    "\n",
    "        param_grid = [\n",
    "            {'kernel':['linear'], 'C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]},\n",
    "            {'kernel':['rbf'], 'C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]},\n",
    "            {'gamma':[0.0001, 0.001, 0.01, 0.1, 1.0]}\n",
    "        ]\n",
    "        svr = SVR()\n",
    "        grid_cv = GridSearchCV(svr, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1)\n",
    "        grid_cv.fit(X_train, y_train)\n",
    "        print(\"최적 하이퍼 파라미터:\\n\", grid_cv.best_params_)\n",
    "\n",
    "        svr_train_pred = grid_cv.predict(X_train)\n",
    "        svr_test_pred = grid_cv.predict(X_test)\n",
    "\n",
    "        return({'trainPrediction':svr_train_pred, 'testPrediction':svr_test_pred})\n",
    "    \n",
    "    # ARIMA\n",
    "    def ARIMA_model(self, y_train, n_periods=5):\n",
    "\n",
    "        auto_arima_model = auto_arima(y_train, \n",
    "                                      start_p=0, max_p=10, \n",
    "                                      start_q=0, max_q=10, \n",
    "                                      seasonal=False,\n",
    "                                      d=1,\n",
    "                                      trace=False,\n",
    "                                      error_action='ignore',  \n",
    "                                      suppress_warnings=True, \n",
    "                                      stepwise=False,\n",
    "                            )\n",
    "        auto_arima_model.fit(y_train)\n",
    "        arima_test_pred = auto_arima_model.predict(n_periods=n_periods)\n",
    "\n",
    "        print(auto_arima_model)\n",
    "\n",
    "        return({'testPrediction':arima_test_pred})\n",
    "    \n",
    "    def LSTM_model(self, X_train, X_test, y_train, y_test, epochs=50):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : Array\n",
    "            Train input data, shape=(nrow, lag, ncol)\n",
    "        X_test : Array\n",
    "            Test input data, shape=(nrow, lag, ncol)\n",
    "        y_train : Array\n",
    "            Train input data, shape=(nrow,)\n",
    "        y_test : Array\n",
    "            Train input data, shape=(nrow,)\n",
    "        epochs : int\n",
    "            LSTM 학습횟수\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        trainPrediction : Array\n",
    "            Train Prediction\n",
    "        testPrediction : Array\n",
    "            Test Prediction\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # LSTM의 구조\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(8, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, activation='relu')) # 하나의 층 8개의 노드, return_sequences=True 필수\n",
    "        model.add(LSTM(4, activation='relu', return_sequences=False)) # 하나의층, 4개의 노드, 마지막에는 return_sequences=False\n",
    "        model.add(Dense(1)) # 노드가 하나인 구조를 만들었다 (하나의 예측값으로 표현하기 위해)\n",
    "\n",
    "        # model compile\n",
    "        model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "        # fit network\n",
    "        history = model.fit(X_train, y_train, epochs=epochs, verbose=0, shuffle=False) # epochs : 반복횟수\n",
    "\n",
    "        lstm_train_pred = model.predict(X_train)\n",
    "        lstm_test_pred = model.predict(X_test)\n",
    "\n",
    "        return({'trainPrediction':lstm_train_pred, 'testPrediction':lstm_test_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f90d9be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Sun Jul 31 20:18:12 2022\n",
    "\n",
    "@author: Junhyun\n",
    "\"\"\"\n",
    "\n",
    "class Recursive_Bayesian_Ensemble_Model():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.ts = TimeSeriesRegression()\n",
    "        \n",
    "        \n",
    "    def EnsembleWeight(self, y_test, ensembleModel):\n",
    "        \n",
    "        # test loss of each prediction model\n",
    "        ridge_mse = mean_squared_error(y_test, ensembleModel['ridgeTestPrediction'])\n",
    "        rf_mse = mean_squared_error(y_test, ensembleModel['rfTestPrediction'])\n",
    "        svr_mse = mean_squared_error(y_test, ensembleModel['svrTestPrediction'])\n",
    "        arima_mse = mean_squared_error(y_test, ensembleModel['arimaTestPrediction'])\n",
    "\n",
    "        # Fitness weight of each model\n",
    "        fitnessSum = (1/ridge_mse + 1/rf_mse + 1/svr_mse + 1/arima_mse) # MSE -> fitness Weight\n",
    "        ridge_fitWeight = (1/ridge_mse)  / fitnessSum\n",
    "        rf_fitWeight = (1/rf_mse)  / fitnessSum\n",
    "        svr_fitWeight = (1/svr_mse) / fitnessSum\n",
    "        arima_fitWeight = (1/arima_mse) / fitnessSum\n",
    "        \n",
    "        fitWeight = {'Ridge_FitWeight' : ridge_fitWeight, 'RF_FitWeight':rf_fitWeight, 'SVR_FitWeight' : svr_fitWeight, 'ARIMA_FitWeight' : arima_fitWeight}\n",
    "        \n",
    "        return(fitWeight)\n",
    "    \n",
    "    def EnsemblePrediction(self, X_train, X_test, y_train, y_test, fitWeight):\n",
    "    \n",
    "        ridge = self.ts.Ridge_regression(X_train, X_test, y_train, y_test)\n",
    "        rf = self.ts.Randomforest_regression(X_train, X_test, y_train, y_test)\n",
    "        svr = self.ts.Supportvector_regression(X_train, X_test, y_train, y_test)\n",
    "        arima = self.ts.ARIMA_model(y_train, y_test.shape[0])\n",
    "        \n",
    "        RBEM_train_pred = (ridge['trainPrediction'] * fitWeight['Ridge_FitWeight']) + (rf['trainPrediction'] * fitWeight['RF_FitWeight']) + (svr['trainPrediction'] * fitWeight['SVR_FitWeight'])\n",
    "        RBEM_test_pred = (ridge['testPrediction'] * fitWeight['Ridge_FitWeight']) + (rf['testPrediction'] * fitWeight['RF_FitWeight']) + (svr['testPrediction'] * fitWeight['SVR_FitWeight'])+ arima['testPrediction'] * fitWeight['ARIMA_FitWeight']\n",
    "        \n",
    "        return(\n",
    "            {\n",
    "             'trainPrediction' : RBEM_train_pred, 'testPrediction':RBEM_test_pred, \n",
    "             'ridgeTrainPrediction':ridge['trainPrediction'], 'ridgeTestPrediction':ridge['testPrediction'],\n",
    "             'rfTrainPrediction' : rf['trainPrediction'], 'rfTestPrediction' : rf['testPrediction'],\n",
    "             'svrTrainPrediction' : svr['trainPrediction'], 'svrTestPrediction' : svr['testPrediction'],\n",
    "            'arimaTestPrediction' : arima['testPrediction']\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    # Recursive Bayesian Update\n",
    "    def BayesianUpdate(self, Prior, Likelihood):\n",
    "        \n",
    "        posterior_Sum = Prior['Ridge_FitWeight']*Likelihood['Ridge_FitWeight'] + Prior['RF_FitWeight']*Likelihood['RF_FitWeight']+Prior['SVR_FitWeight']*Likelihood['SVR_FitWeight'] + Prior['ARIMA_FitWeight']*Likelihood['ARIMA_FitWeight']\n",
    "        Ridge_Updated_Weight = Prior['Ridge_FitWeight']*Likelihood['Ridge_FitWeight'] / posterior_Sum\n",
    "        RF_Updated_Weight = Prior['RF_FitWeight']*Likelihood['RF_FitWeight'] / posterior_Sum\n",
    "        SVR_Updated_Weight = Prior['SVR_FitWeight']*Likelihood['SVR_FitWeight'] / posterior_Sum\n",
    "        ARIMA_Updated_Weight =  Prior['ARIMA_FitWeight']*Likelihood['ARIMA_FitWeight'] / posterior_Sum\n",
    "\n",
    "        updatedFitWeight = {'Ridge_FitWeight' : Ridge_Updated_Weight, 'RF_FitWeight':RF_Updated_Weight, 'SVR_FitWeight' : SVR_Updated_Weight, 'ARIMA_FitWeight':ARIMA_Updated_Weight}\n",
    "        \n",
    "        return(updatedFitWeight)\n",
    "    \n",
    "    # Recursive Bayesian Ensemble Model\n",
    "    def RBEM_model(self, X, y, trainCycle=10, predictionCycle=5, Cycle=5):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Array  \n",
    "            Input data, shape=(nrow, lag, ncol)\n",
    "        y : Array\n",
    "            Output data, shape=(nrow,)\n",
    "        trainCycle : int\n",
    "            며칠 주기로 학습할 것인지 \n",
    "        predictionCycle : int\n",
    "            며칠 주기로 예측할 것인지\n",
    "        Cycle : int\n",
    "            위 과정을 몇번 반복할 것인지\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        recursive_test_pred : Array\n",
    "            test 데이터를 recursive하게 예측한 결과\n",
    "\n",
    "\n",
    "        예시)\n",
    "        1row = 1일일때, \n",
    "        trainCycle = 5 -> 5일 주기로 학습\n",
    "        predictionCycle = 2 -> 2일 주기로 예측\n",
    "\n",
    "        1월 1일 데이터가 있다고 가정\n",
    "\n",
    "        - 1월 1일 ~ 1월 5일 (5일) 학습 후, 1월 6일~1월 7일 (2일) 예측 (1cycle)\n",
    "        - 1월 3일 ~ 1월 7일 (5일) 학습 후, 1월 8일~1월 9일 (2일) 예측 (2cycle) (1월 6일은 실제 데이터임 (예측한 데이터 X)) (현재시점까지 왔다고 가정)\n",
    "        - 1월 5일 ~ 1월 9일 (5일) 학습 후, 1월 10일~1월 11일 (2일) (1일) 예측 (3cycle) (1월 7일은 실제 데이터임 (예측한 데이터 X)) (현재시점까지 왔다고 가정)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # Recursive Prediction\n",
    "        RBEM_test_pred = np.array([])\n",
    "        Ridge_test_pred = np.array([])\n",
    "        RF_test_pred = np.array([])\n",
    "        SVR_test_pred = np.array([])\n",
    "        ARIMA_test_pred = np.array([])\n",
    "        y_test = np.array([])\n",
    "        \n",
    "        # Prior of Ensemble Weight\n",
    "        prior_fitWeight = {'Ridge_FitWeight' : 1/3, 'RF_FitWeight':1/3, 'SVR_FitWeight' : 1/3, 'ARIMA_FitWeight':1/3}\n",
    "        \n",
    "        for i in range(Cycle):\n",
    "\n",
    "            # Recursive prediction\n",
    "            recursive_X_train = X[(predictionCycle*i):(trainCycle+predictionCycle*i)]\n",
    "            recursive_X_test = X[(trainCycle+predictionCycle*i):(trainCycle+predictionCycle*(i+1))]\n",
    "            \n",
    "            recursive_y_train = y[(predictionCycle*i):(trainCycle+predictionCycle*i),]\n",
    "            recursive_y_test = y[(trainCycle+predictionCycle*i):(trainCycle+predictionCycle*(i+1)),]\n",
    "            \n",
    "            y_test = np.append(y_test, recursive_y_test.values)\n",
    "            \n",
    "            ensemble_pred = self.EnsemblePrediction(recursive_X_train, recursive_X_test, recursive_y_train, recursive_y_test, prior_fitWeight)\n",
    "                            \n",
    "            # Bayesian Ensemble Prediction\n",
    "            RBEM_test_pred = np.append(RBEM_test_pred, ensemble_pred['testPrediction'])\n",
    "            \n",
    "            # Comprised Model of Ensemble Model\n",
    "            Ridge_test_pred = np.append(Ridge_test_pred, ensemble_pred['ridgeTestPrediction'])                    \n",
    "            RF_test_pred = np.append(RF_test_pred, ensemble_pred['rfTestPrediction'])                  \n",
    "            SVR_test_pred = np.append(SVR_test_pred, ensemble_pred['svrTestPrediction'])\n",
    "            ARIMA_test_pred = np.append(ARIMA_test_pred, ensemble_pred['arimaTestPrediction'])\n",
    "            \n",
    "            # likelihood of Ensemble Weight\n",
    "            likelihood_fitWeight = self.EnsembleWeight(recursive_y_test.values, ensemble_pred)\n",
    "            \n",
    "            # Bayesian Update Ensemble Weights\n",
    "            prior_fitWeight = self.BayesianUpdate(prior_fitWeight, likelihood_fitWeight)\n",
    "            \n",
    "        return(\n",
    "            { \n",
    "                'RBEM_test_pred' : RBEM_test_pred,\n",
    "                'Ridge_test_pred': Ridge_test_pred,\n",
    "                'RF_test_pred' : RF_test_pred,\n",
    "                'SVR_test_pred' : SVR_test_pred,\n",
    "                'ARIMA_test_pred' : ARIMA_test_pred,\n",
    "                'y_test' : y_test\n",
    "            }\n",
    "        \n",
    "        )\n",
    "        \n",
    "    def maxCycleNum(self, data, trainCycle=10, predictionCycle=5):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : DataFrame\n",
    "            data\n",
    "        trainCycle : int\n",
    "            며칠 주기로 학습할 것인지 \n",
    "        predictionCycle : int\n",
    "            며칠 주기로 예측할 것인지\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        maxCycle : int\n",
    "            Recursive 하게 예측할 수 있는 최대 cycle 수\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        maxCycle = int((data.shape[0] - trainCycle) / predictionCycle) - 1\n",
    "\n",
    "        print('Max Cycle Number : %d' % maxCycle)\n",
    "\n",
    "        return(maxCycle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0d79de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99886be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/2010-2011 Solar home electricity data(perCustomer).csv')\n",
    "GC = df.iloc[:,140:141]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "618d87dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Cycle Number : 356\n"
     ]
    }
   ],
   "source": [
    "ts = TimeSeriesRegression()\n",
    "\n",
    "reframed = ts.TimeSeriesDataTransform(GC, lag=48)\n",
    "\n",
    "X = reframed.iloc[:,0:-1]\n",
    "y = reframed.iloc[:,-1]\n",
    "\n",
    "\n",
    "RBEM = Recursive_Bayesian_Ensemble_Model()\n",
    "\n",
    "maxCycle = RBEM.maxCycleNum(X, trainCycle=336, predictionCycle=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb77f748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha : 0.99\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 8, 'min_samples_leaf': 12, 'min_samples_split': 16, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'C': 0.1, 'kernel': 'linear'}\n",
      " ARIMA(4,1,1)(0,0,0)[0] intercept\n",
      "alpha : 0.99\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 12, 'min_samples_leaf': 8, 'min_samples_split': 8, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'C': 0.1, 'kernel': 'linear'}\n",
      " ARIMA(2,1,3)(0,0,0)[0] intercept\n",
      "alpha : 0.99\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 12, 'min_samples_leaf': 8, 'min_samples_split': 8, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'C': 0.1, 'kernel': 'linear'}\n",
      " ARIMA(1,1,4)(0,0,0)[0] intercept\n",
      "alpha : 0.99\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 10, 'min_samples_leaf': 8, 'min_samples_split': 16, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'C': 0.1, 'kernel': 'linear'}\n",
      " ARIMA(1,1,4)(0,0,0)[0] intercept\n",
      "alpha : 0.99\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 8, 'min_samples_leaf': 8, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n"
     ]
    }
   ],
   "source": [
    "RBEM_pred = RBEM.RBEM_model(X, y, trainCycle=336, predictionCycle=48, Cycle=maxCycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd3d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "RBEM_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b54f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbem_mse = mean_squared_error(RBEM_pred['RBEM_test_pred'],RBEM_pred['y_test'])\n",
    "ridge_mse = mean_squared_error(RBEM_pred['Ridge_test_pred'],RBEM_pred['y_test'])\n",
    "rf_mse = mean_squared_error(RBEM_pred['RF_test_pred'],RBEM_pred['y_test'])\n",
    "svr_mse = mean_squared_error(RBEM_pred['SVR_test_pred'],RBEM_pred['y_test'])\n",
    "arima_mse = mean_squared_error(RBEM_pred['ARIMA_test_pred'],RBEM_pred['y_test'])\n",
    "mean_mse = (ridge_mse+rf_mse+svr_mse+arima_mse) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b63da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RBEM MSE : %f' %rbem_mse)\n",
    "print('Ridge MSE : %f' %ridge_mse)\n",
    "print('RF MSE : %f' %rf_mse)\n",
    "print('SVR MSE : %f' %svr_mse)\n",
    "print('ARIMA MSE : %f' %arima_mse)\n",
    "print('Mean MSE : %f' %mean_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
